{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To Use HuggingFace Datasets With MLX Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image has shape  (784,)\n",
      "The image should display a  8\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from typing import Dict, Any\n",
    "from types import SimpleNamespace\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import mlx.core as mx\n",
    "import mlx.data as dx\n",
    "\n",
    "# Convert the Hugging Face dataset to the custom format\n",
    "def huggingface_to_array_of_dict(dataset):    \n",
    "    return [{\"image\": np.array(image).copy(), \"label\": label}\n",
    "            for label, image in zip(dataset['label'], dataset['image'])]\n",
    "\n",
    "# Convert the Hugging Face dataset to a stream of batches\n",
    "def hf_dataset_to_mlx_stream(dataset, shuffle=False, bs=256, prefetch_size=4, num_threads=4):\n",
    "    buffer = dx.buffer_from_vector(huggingface_to_array_of_dict(dataset))\n",
    "    if shuffle:\n",
    "        buffer = buffer.shuffle()\n",
    "    \n",
    "    return (\n",
    "        buffer\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\").reshape(-1) / 255) # flat tensor because we gonna use a MLP model      \n",
    "        .batch(bs)\n",
    "        .prefetch(prefetch_size, num_threads) # fetch batches in background threads\n",
    "    )\n",
    "\n",
    "# Load the MNIST dataset from Hugging Face\n",
    "ds = load_dataset(\"ylecun/mnist\")\n",
    "\n",
    "# Transform the dataset to streams\n",
    "train_stream = hf_dataset_to_mlx_stream(ds['train'], shuffle=True)\n",
    "\n",
    "# Iterate on the batches\n",
    "train_stream.reset()\n",
    "for batch_counter, batch in enumerate(train_stream):\n",
    "    (X, y) = mx.array(batch['image']), mx.array(batch['label'])\n",
    "\n",
    "    print('The image has shape ', X[0].shape)    \n",
    "    print('The image should display a ', y[0].item())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 60000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Dataset To MLX Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Config To Keep Config/HyperParams Organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use only the training set for now, splitting it into two parts:\n",
    "- Training Set: 80% for training our model.\n",
    "- Validation Set: 20% for checking the model’s accuracy at each epoch.\n",
    "\n",
    "We’ll keep the test set aside for the final evaluation to see how our model performs on completely unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ylecun/mnist\")\n",
    "split_ds = ds['train'].train_test_split(test_size=0.2)\n",
    "ds = {\n",
    "    'train': split_ds['train'],\n",
    "    'val': split_ds['test'],\n",
    "    'test': ds['test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds['train']['image'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mission is to turn this into a mx.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Hugging Face Dataset To MLX Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlx.data as dx\n",
    "\n",
    "# Convert the content of the dataset into numpy arrays\n",
    "def huggingface_to_array_of_dict(dataset):    \n",
    "    return [{\"image\": np.array(image).copy(), \"label\": label}\n",
    "            for label, image in zip(dataset['label'], dataset['image'])]\n",
    "\n",
    "# Convert the Hugging Face dataset to a stream of batches\n",
    "def hf_dataset_to_mlx_stream(dataset, shuffle=False, bs=256, prefetch_size=4, num_threads=4):\n",
    "    numpy_data = huggingface_to_array_of_dict(dataset)\n",
    "\n",
    "    # This might look tedious but these little assert will save you a lot of time\n",
    "    assert type(numpy_data) == list, \"Processed data should be a list\"\n",
    "    assert len(numpy_data) == len(dataset), \"Output length should match input length\"\n",
    "    assert type(numpy_data[0]) == dict, \"Each item should be a dictionary\"\n",
    "    assert 'image' in numpy_data[0] and 'label' in numpy_data[0], \"Each dict should have 'image' and 'label' keys\"\n",
    "    assert type(numpy_data[0]['image']) == np.ndarray, f\"{type(numpy_data[0]['image'])} should be a numpy array\"\n",
    "\n",
    "    buffer = dx.buffer_from_vector(numpy_data)\n",
    "    if shuffle:\n",
    "        buffer = buffer.shuffle()    \n",
    "    \n",
    "    return (\n",
    "        buffer\n",
    "        .to_stream()\n",
    "        .key_transform(\"image\", lambda x: x.astype(\"float32\").reshape(-1) / 255) # flat tensor because we gonna use a MLP model      \n",
    "        .batch(bs)\n",
    "        .prefetch(prefetch_size, num_threads) # fetch batches in background threads\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping Params Oganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "cfg = SimpleNamespace()\n",
    "# These are more Loading Param\n",
    "cfg.prefetch = 4\n",
    "cfg.num_threads = 8\n",
    "cfg.batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stream()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stream = hf_dataset_to_mlx_stream(ds['train'],\n",
    "                                        shuffle=True,\n",
    "                                        bs=cfg.batch_size,\n",
    "                                        prefetch_size=cfg.prefetch,\n",
    "                                        num_threads=cfg.num_threads)\n",
    "train_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally We Can Iterate On The Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image should display a  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch time: 0.05062 (s)\n"
     ]
    }
   ],
   "source": [
    "# helper to display an image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def np_show_img(array, title=''):\n",
    "    if array.ndim == 1:  # If rank 1, reshape to 2D\n",
    "        array = array.reshape(28, 28)\n",
    "    plt.imshow(array, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def one_epoch():\n",
    "    train_stream.reset()\n",
    "    for batch in train_stream:    \n",
    "        (X, y) = mx.array(batch['image']), mx.array(batch['label'])\n",
    "        \n",
    "        # we want a flat tensor (batch_size,pixels) since we gonna use a MLP instead of a CNN\n",
    "        assert X.ndim == 2, X.shape\n",
    "        assert X.shape == (cfg.batch_size, 784), X.shape\n",
    "        assert X.dtype == mx.float32, X.dtype\n",
    "        assert y.shape == (cfg.batch_size,), y.shape\n",
    "            \n",
    "        print('The image should display a ', y[0].item())\n",
    "        np_show_img(X[0])\n",
    "        break # USE OPTIMIZER HERE\n",
    "\n",
    "# ADD YOUR EPOCH LOOP, ETC HERE\n",
    "tic = time.perf_counter()\n",
    "one_epoch()\n",
    "toc = time.perf_counter()\n",
    "print(f\"epoch time: {toc - tic:.5f} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
